# OpenAI Configuration
# Required: Your OpenAI API key for GPT-5 access
OPENAI_API_KEY=your_openai_api_key_here

# Optional: GPT-5 model to use (default: gpt-5-mini)
# Options: gpt-5, gpt-5-mini, gpt-5-nano, gpt-5-codex
# - gpt-5: Best for complex reasoning, broad world knowledge, and multi-step agentic tasks
# - gpt-5-mini: Cost-optimized reasoning and chat; balances speed, cost, and capability (default)
# - gpt-5-nano: High-throughput tasks, especially simple instruction-following or classification
# - gpt-5-codex: Optimized for code generation, refactoring, debugging, and code explanations
OPENAI_MODEL=gpt-5-mini

# Optional: Reasoning effort level (default: medium)
# Options: minimal, low, medium, high
# - minimal: Very few reasoning tokens, fastest time-to-first-token
# - low: Favors speed and fewer tokens
# - medium: Balanced reasoning and speed (default)
# - high: More thorough reasoning, best for complex tasks
OPENAI_REASONING_EFFORT=medium

# Optional: Output verbosity level (default: medium)
# Options: low, medium, high
# - low: Concise answers, shorter code with minimal commentary
# - medium: Balanced output length
# - high: Thorough explanations, longer structured code with inline explanations
OPENAI_VERBOSITY=medium

# Optional: Maximum tokens for output (default: 4096)
OPENAI_MAX_TOKENS=4096

# Server Configuration
# Optional: Server name (default: mcp-consultant)
SERVER_NAME=mcp-consultant

# Optional: Server version (default: 0.1.0)
SERVER_VERSION=0.1.0

# Optional: Port for HTTP transport (default: 3000)
# Note: Currently only stdio transport is implemented
PORT=3000

# Optional: Transport mode (default: stdio)
# Options: stdio, streaming
TRANSPORT=stdio

# Logging Configuration
# Optional: Log level for structured logging (default: info)
# Options: debug, info, warn, error
# - debug: Detailed information for debugging (includes LLM requests, context gathering)
# - info: General informational messages (tool calls, responses, lifecycle events)
# - warn: Warning messages for potentially problematic situations
# - error: Error messages for failures
LOG_LEVEL=info

# Optional: Node environment (affects log formatting)
# - development: Pretty-printed, colorized logs with timestamps
# - production: JSON-formatted logs for log aggregation systems
NODE_ENV=development

# Context Gathering Configuration
# Optional: Enable Serena MCP integration (default: true)
ENABLE_SERENA=true

# Optional: Enable Memory MCP integration (default: true)
ENABLE_MEMORY=true

# Optional: Enable CCLSP MCP integration (default: true)
ENABLE_CCLSP=true

# Optional: Maximum tokens for context gathering (default: 32000)
MAX_CONTEXT_TOKENS=32000

# Optional: Include file content in context (default: true)
INCLUDE_FILE_CONTENT=true

# Optional: Include git history in context (default: false)
INCLUDE_GIT_HISTORY=false
